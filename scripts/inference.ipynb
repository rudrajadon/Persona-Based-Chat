{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHdUuPktbQe0"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "import logging\n",
        "\n",
        "# Suppress unnecessary logging\n",
        "logging.getLogger(\"transformers\").setLevel(logging.CRITICAL)\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"rudrajadon18/Llama-2-7b-chat-finetune\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Create the pipeline\n",
        "pipe = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    pad_token_id=tokenizer.eos_token_id  # Handle padding for better output\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt\n",
        "persona_b = \"I love traveling, reading romance novels, and trying new cuisines. I have a deep passion for animals and enjoy volunteering at shelters. I enjoy hiking in the mountains and spending time at the beach. I also like to write about my experiences on my blog. I am a carnivore who loves sharing my experiences with friends over a good meal.\"\n",
        "question = \"What do you think about travelling?\"\n",
        "prompt = f\"<persona_b>{persona_b}<s>[INST] {question} [/INST]\"\n",
        "\n",
        "# Generate text\n",
        "result = pipe(prompt, max_length=200)  # You can adjust max_length as needed\n",
        "print(result[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "j6vW6x9obfCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate response based on user input\n",
        "\n",
        "def generate_response():\n",
        "    # Take user input for Persona B and the question\n",
        "    persona_b = input(\"Enter Persona B information: \")\n",
        "    question = input(\"Enter your question: \")\n",
        "\n",
        "    # Construct the prompt\n",
        "    prompt = f\"<persona_b>{persona_b}<s>[INST] {question} [/INST]\"\n",
        "\n",
        "    # Generate text\n",
        "    result = pipe(prompt, max_length=200)  # You can adjust max_length as needed\n",
        "\n",
        "    # Print the generated response\n",
        "    print(\"\\nGenerated Response:\")\n",
        "    print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "dWdhxhySbcbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function to interact\n",
        "generate_response()"
      ],
      "metadata": {
        "id": "REbpMLPJbePC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}